{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Your assignment 3 will be similar to assignment 2, this time with the addition of an LLM.\n",
        "\n",
        "If you wish to reuse your assignment 2 scan and incorporate an LLM, you can.\n",
        "\n",
        "**Note:** This assignment will necessitate utilizing the internet, academic databases, or other educational resources to acquire certain skills or knowledge not covered in our course materials. Students are encouraged to explore reputable sources, online tutorials, and community forums to gather the information needed to successfully complete this project. This exploration is an integral part of the learning process, fostering self-directed research skills and a deeper understanding of the subject matter.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MphX2gwihidG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 3: Environment Scanning and Object Detection with LLMs\n",
        "\n",
        "### **1. Environment Scanning Using Scanniverse App**\n",
        "- Utilize the **Scanniverse app** with specific output settings listed below to scan an environment. Include a demonstration of the scanned area in your submission.\n",
        "    - **Note**: The Scanniverse app **only** works on iOS devices. If you have an Android or a different OS, please search for an alternative 3D scanning app that allows you to export 3D models. For those needing to scan an environment or unsure what to scan, you may find a **3D setting online** suitable for Unity.\n",
        "\n",
        "### **2. Dataset Acquisition**\n",
        "- Visit **Roboflow** to find a dataset for the object detection task. This dataset should be relevant to the type of objects you intend to detect within your scanned or selected environment.\n",
        "\n",
        "### **3. Train Your Own Model**\n",
        "- Using the dataset acquired from Roboflow, train your own model to recognize and detect objects within the environment.\n",
        "\n",
        "### **4. Detection and Results Presentation**\n",
        "- Deploy your trained model to detect objects in the scanned environment. Show the results of the detected labels.\n",
        "    - Screenshots or video demonstrations are encouraged to effectively showcase the detection results.\n",
        "\n",
        "### **5. Integration of LLM for Interactive Q&A**\n",
        "- Implement a mechanism in your Unity project that allows users to interact with the output of a Language Learning Model (LLM) such as GPT-3. This system should enable users to ask questions about the detected objects in real-time, receiving informative or narrative responses generated by the LLM.\n",
        "    - **Interactive System Design**: Develop a user interface within Unity where questions can be submitted about detected objects. This could be through text input, voice commands, or selection within the scene.\n",
        "    - **Real-Time LLM Interaction**: Set up a communication protocol between Unity and the Flask server to forward user questions to the LLM and display the generated answers in the Unity environment.\n",
        "    - **Contextual Responses**: Ensure the LLM can generate responses that are relevant to the specific objects detected in the environment, enhancing the educational or exploratory value of the project.\n",
        "\n",
        "**Submission Guidelines**:\n",
        "Ensure your submission includes:\n",
        "- A brief description of the scanned environment or the 3D setting selected.\n",
        "- Details on the dataset from Roboflow, including the type of objects and the number of images.\n",
        "- Information on the model training process, including details on the model architecture, training parameters, and any pre-processing steps involved.\n",
        "- Visual evidence of the detection results and the interactive Q&A feature in action within your Unity scene via screen recording.\n",
        "\n",
        "**Evaluation Criteria**:\n",
        "Submissions will be evaluated based on:\n",
        "- The complexity and relevance of the chosen environment.\n",
        "- The appropriateness and quality of the dataset used for training.\n",
        "- The accuracy and efficiency of the trained model in detecting objects.\n",
        "- The innovation, user-friendliness, and functionality of the LLM interactive Q&A feature.\n",
        "- The clarity and detail of the presentation of your results, including the effectiveness of the LLM in providing relevant and engaging responses.\n"
      ],
      "metadata": {
        "id": "uKbAW5Bse2ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Ideas for Assignment 3: LLM Integration\n",
        "\n",
        "For the interactive Q&A feature with LLM integration, consider scenarios where users can gain insights, learn history, or explore concepts through engaging with detected objects. Below are some examples to inspire your projects:\n",
        "\n",
        "#### Historical Landmarks\n",
        "- **Scenario**: After scanning a historical site, users can ask about the history of specific structures, the significance of inscriptions, or the stories behind statues.\n",
        "- **Example Interaction**: \"Tell me more about this statue.\" The LLM could provide historical context, artist information, or related anecdotes.\n",
        "\n",
        "#### Public Parks\n",
        "- **Scenario**: With a focus on diverse vegetation and park features, users could inquire about plant species, the history of the park, or the purpose of different areas.\n",
        "- **Example Interaction**: \"What species of tree is this?\" The LLM responds with the tree's name, botanical characteristics, and any folklore associated.\n",
        "\n",
        "#### Personal Workspace\n",
        "- **Scenario**: For a scanned personal workspace, the system allows inquiries about the functionality of tools, the inspiration behind artworks, or recommendations for organization.\n",
        "- **Example Interaction**: \"How do I use this drawing tablet?\" The LLM provides a brief guide or directs to tutorial resources.\n",
        "\n",
        "#### Urban Street Scenes\n",
        "- **Scenario**: In a vibrant street scene, users can learn about architectural styles, the history of buildings, or urban planning concepts.\n",
        "- **Example Interaction**: \"What architectural style is this building?\" The LLM offers an explanation, historical significance, and examples of similar structures.\n",
        "\n",
        "#### Home Interior\n",
        "- **Scenario**: Scanning a home interior allows users to ask about interior design styles, the history of certain appliances, or tips for home improvement.\n",
        "- **Example Interaction**: \"What era is this chair from?\" The LLM details the design era, characteristics, and cultural context of the furniture piece.\n",
        "\n",
        "#### Educational Institutions\n",
        "- **Scenario**: By scanning educational spaces, users can explore the history of the institution, inquire about specific academic tools, or learn about artworks displayed.\n",
        "- **Example Interaction**: \"What is this device used for in the lab?\" The LLM provides a simple explanation of the device's purpose and its application in experiments.\n",
        "\n",
        "These examples are designed to leverage the object detection capabilities and the rich, informative output of LLMs to create an interactive and educational experience within the Unity environment. Consider how users can interact with the environment to not only receive information but also stimulate curiosity and learning through engaging questions and LLM-generated responses.\n"
      ],
      "metadata": {
        "id": "uhFHZr4Amf7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the Scaniverse app on any iOS hand held device.\n",
        "2. Click on the new scan plus button below.\n",
        "3. Select large object / area as the scan size.\n",
        "4. Scan your environment, follow the instructions.\n",
        "   - **Note**: For best results in getting an accurate scan, slow down, get close up, and don't be afraid to rescan if your desired output is not ideal.\n",
        "5. **IMPORTANT**: select your processing mode as **Detail** for the best quality in Unity.\n",
        "6. Click **save** > **share** > **Export model**, choose **OBJ** for ease, and email it to yourself.\n",
        "7. Import into Unity"
      ],
      "metadata": {
        "id": "eruf1geCkCRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If importing a scene from Scaniverse or online, Unity supports a variety of 3D model formats, with the most common being **FBX**, **OBJ**, and **3DS**. For optimal performance and compatibility, your 3D models should ideally consist of a 3D mesh and associated textures. If you encounter any issues importing your models or need further assistance, please don't hesitate to contact Sunny for help."
      ],
      "metadata": {
        "id": "OiRki78XkE4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Disclaimer on Object Detection in Unity**:\n",
        "Object detection within Unity environments can present unique challenges and may not always yield perfect results on the first try. It's important to understand that achieving accurate detection might require adjustments to your 3D environment, dataset or model parameters. Experimentation and iteration are key components of developing a successful object detection system in Unity. Be prepared to refine your approach based on the results you observe.\n"
      ],
      "metadata": {
        "id": "cqSat50ekG87"
      }
    }
  ]
}